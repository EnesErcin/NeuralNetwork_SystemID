{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from func import neuron_layer,neuron_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mosttt  3\n"
     ]
    }
   ],
   "source": [
    "my_layers = neuron_layers([1,2,3,2],0.0000005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " |||| In neuron 0\n",
      "Forward Calculations || W.x + b || == a \n",
      "\n",
      "W -> \n",
      " [[1.]\n",
      " [1.]], x -> \n",
      " [[2]], b -> \n",
      " [[0.97405567]\n",
      " [0.80565397]]\n",
      "----\n",
      "a -> [[2.97405567]\n",
      " [2.80565397]]\n",
      "Nonlinear ||σ(a) = y|| == a \n",
      "\n",
      "a -> [[2.97405567]\n",
      " [2.80565397]] \n",
      "σ(a) -> [[0.95138819]\n",
      " [0.94298059]]\n",
      "-------------------------\n",
      "\n",
      "\n",
      " \n",
      " |||| In neuron 1\n",
      "Forward Calculations || W.x + b || == a \n",
      "\n",
      "W -> \n",
      " [[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]], x -> \n",
      " [[0.95138819]\n",
      " [0.94298059]], b -> \n",
      " [[0.42948737]\n",
      " [0.25157042]\n",
      " [0.68798628]]\n",
      "----\n",
      "a -> [[2.32385615]\n",
      " [2.1459392 ]\n",
      " [2.58235506]]\n",
      "Nonlinear ||σ(a) = y|| == a \n",
      "\n",
      "a -> [[2.32385615]\n",
      " [2.1459392 ]\n",
      " [2.58235506]] \n",
      "σ(a) -> [[0.91083362]\n",
      " [0.8952887 ]\n",
      " [0.92971731]]\n",
      "-------------------------\n",
      "\n",
      "Forward Calculations || W.x + b || == a \n",
      "\n",
      "W -> \n",
      " [[1. 1. 1.]\n",
      " [1. 1. 1.]], x -> \n",
      " [[0.91083362]\n",
      " [0.8952887 ]\n",
      " [0.92971731]], b -> \n",
      " [[0.17721056]\n",
      " [0.46902924]]\n",
      "----\n",
      "a -> [[2.91305019]\n",
      " [3.20486887]]\n",
      "-------------------------\n",
      "\n",
      "\n",
      " \n",
      " |||| In neuron 2\n",
      "Forward Calculations || W.x + b || == a \n",
      "\n",
      "W -> \n",
      " [[1. 1. 1.]\n",
      " [1. 1. 1.]], x -> \n",
      " [[0.91083362]\n",
      " [0.8952887 ]\n",
      " [0.92971731]], b -> \n",
      " [[0.17721056]\n",
      " [0.46902924]]\n",
      "----\n",
      "a -> [[2.91305019]\n",
      " [3.20486887]]\n"
     ]
    }
   ],
   "source": [
    "data = np.reshape(np.array([2]) , (1,1))\n",
    "expected = np.reshape(np.array([2]), (1,1))\n",
    "\n",
    "err , out = my_layers.calc_output(data,expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X values \n",
      "[[2]], W values \n",
      "[[1.]\n",
      " [1.]], Sig values\n",
      "[[0.95138819]\n",
      " [0.94298059]]\n",
      "X values \n",
      "[[0.95138819]\n",
      " [0.94298059]], W values \n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]], Sig values\n",
      "[[0.91083362]\n",
      " [0.8952887 ]\n",
      " [0.92971731]]\n",
      "X values \n",
      "[[0.91083362]\n",
      " [0.8952887 ]\n",
      " [0.92971731]], W values \n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]], Sig values\n",
      "[[0.]\n",
      " [0.]]\n",
      "\n",
      " Error\n",
      " [[0.83366066]\n",
      " [1.451709  ]]\n"
     ]
    }
   ],
   "source": [
    "for i in my_layers.layers:\n",
    "    print(\"X values \\n{}, W values \\n{}, Sig values\\n{}\".format(i.x,i.w,i.sig))\n",
    "\n",
    "#print(\"\\n\\n\",(out-expected)**2)\n",
    "#print(err) ## Mean squarer error\n",
    "\n",
    "print(\"\\n Error\\n {}\".format(my_layers.layers[-1].j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95138819],\n",
       "       [0.94298059]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_layers.layers[1].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! Neuron  2\n",
      "(2, 1) (3, 1) <class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'> (3, 1)\n",
      "Finally (2, 3)\n",
      "!!! Neuron  1\n",
      "(1, 3) (2, 1) <class 'numpy.ndarray'>\n",
      "Sigmoid shape (3, 1), Passed down shape (1, 3)\n",
      "(1, 3)\n",
      "<class 'numpy.ndarray'> (2, 1)\n",
      "Finally (3, 2)\n",
      "!!! Neuron  0\n",
      "(1, 2) (1, 1) <class 'numpy.ndarray'>\n",
      "Sigmoid shape (2, 1), Passed down shape (1, 2)\n",
      "(1, 2)\n",
      "<class 'numpy.ndarray'> (1, 1)\n",
      "Finally (2, 1)\n"
     ]
    }
   ],
   "source": [
    "da_dw = -2*err\n",
    "\n",
    "##### 1- w_1*x  + b_1 = a_0      || Layer 1\n",
    "##### 2- c_0 = σ(a_0)\n",
    "##### 3- w_2*c_0 + b_2 = a_1     || Layer 2\n",
    "##### 4- c_1 = σ(a_1) \n",
    "##### 5- w_3*c_1 + b_3 = a_2     || Layer 3 (Output Layer)\n",
    "\n",
    "##### First weigtth derivatives\n",
    "#####\n",
    "##### dJ/dw_2 = [ (dJ/dy)*(dy/da) ] * d_c1\n",
    "##### --> Send for other derivatives dJ/dc = [ (dJ/dy)*(dy/da) ]*w\n",
    "\n",
    "######## dC/dw_2 = (dC/dy)*(dy/da_2)*(da_2/d_c1)*(dc_1/d_a1)*(da_1/dw_2)\n",
    "##### (dJ/dy)   = -2J\n",
    "##### (dy/da_2) = 1\n",
    "##### (da_2/d_c1) = w_3\n",
    "##### (dc_1/d_a1) = -c_1(1-c_1)\n",
    "##### (da_1/dw_2) = c_0\n",
    "\n",
    "##### dw_2 @ layer[1]\n",
    "\n",
    "dJ_da = -2*my_layers.layers[-1].j \n",
    "a = (len(my_layers.layers) - 1 )\n",
    "\n",
    "for i in range(0,3):\n",
    "\n",
    "    print(\"!!! Neuron \",a)\n",
    "    print(np.shape(dJ_da),np.shape(my_layers.layers[a].x),type(my_layers.layers[a].x))\n",
    "\n",
    "    if a == (len(my_layers.layers) - 1 ):\n",
    "        dJ_da = dJ_da.T\n",
    "        # No activation layer\n",
    "    else:\n",
    "        dJ_da = dJ_da * my_layers.layers[a].sig.T\n",
    "        \n",
    "    print(type(my_layers.layers[a].x),np.shape(my_layers.layers[a].x))\n",
    "\n",
    "    dJ_dw = dJ_da.T @  my_layers.layers[a].x.T\n",
    "    \n",
    "    da_dc = my_layers.layers[a].w\n",
    "    \n",
    "    dJ_dc = dJ_da @ da_dc\n",
    "\n",
    "    dJ_da = dJ_dc ## Pass down\n",
    "\n",
    "\n",
    "    print(\"Derivatives of the weigth factos \\n {} \\n\".format(dJ_dw))\n",
    "    print(np.shape(dJ_dw))\n",
    "\n",
    "    a = a-1\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,1) (3,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m my_layers\u001b[39m.\u001b[39;49mback_prop()\n",
      "File \u001b[0;32m~/Desktop/NeuralNetwork_SystemID/PID_NN_wPY/Act/func.py:58\u001b[0m, in \u001b[0;36mneuron_layers.back_prop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m (\u001b[39m0\u001b[39m,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m     57\u001b[0m     cnt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size\u001b[39m-\u001b[39ma\n\u001b[0;32m---> 58\u001b[0m     da_dc,dJ_dw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers[cnt]\u001b[39m.\u001b[39;49mbackprop(da_dc)\n\u001b[1;32m     59\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m@ \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m da_dc \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(cnt,dJ_dw))\n\u001b[1;32m     60\u001b[0m \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/NeuralNetwork_SystemID/PID_NN_wPY/Act/func.py:166\u001b[0m, in \u001b[0;36moutput_layer.backprop\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    164\u001b[0m dj \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mj\n\u001b[1;32m    165\u001b[0m dw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx\n\u001b[0;32m--> 166\u001b[0m dj_dw \u001b[39m=\u001b[39m dj\u001b[39m*\u001b[39;49mdw\n\u001b[1;32m    168\u001b[0m dj_dc \u001b[39m=\u001b[39m dj\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw\n\u001b[1;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr\u001b[39m*\u001b[39mdj_dw\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,1) (3,1) "
     ]
    }
   ],
   "source": [
    "my_layers.back_prop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
